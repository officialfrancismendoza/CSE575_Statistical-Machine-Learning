{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION USING NEURAL NETWORKS AND DEEP LEARNING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROGRAMMER:** Francis Mendoza \n",
    "\n",
    "**ASUID:** 1213055998\n",
    "\n",
    "**EMAIL:** fmendoz7@asu.edu\n",
    "\n",
    "**CLASS:** CSE575, Wednesday 15:00-16:15 hrs MST, Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Assessing Original Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIFIED CODE TO RUN: Just kept lr=0.1 for Adadelta method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFIED THIS LINE, AS ORIGINAL BOILERPLATE DID NOT RUN CORRECTLY \n",
    "\"\"\"\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1, rho=0.95, epsilon=None, decay=0.0),\n",
    "              metrics=['accuracy'])\n",
    "\"\"\"\n",
    "\n",
    "# REPLACED WITH THIS LINE INSTEAD\n",
    "\"\"\"\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# https://keras.io/optimizers/ \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('ORIGINAL BOILERPLATE: Learning Error')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.grid(True)\n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Changing Kernel Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we:\n",
    "* CHANGED FROM BOILERPLATE: Change the kernel size to 5*5\n",
    "* Plot learning errors along the epoch\n",
    "* Report testing error\n",
    "* Report testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten #imported more stuff\n",
    "from keras.optimizers import RMSprop #imported more stuff\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Imported More Stuff\n",
    "#from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "    # Changed Features\n",
    "        # (!!!) Kernel Size = 5x5\n",
    "        # (!!!) Added strides = 1 for first CL and for first MaxPool\n",
    "    \n",
    "    # Unchanged Features\n",
    "        # Feature Maps = 6\n",
    "        # Max Pooling = 2x2\n",
    "model2.add(Conv2D(6, kernel_size=(5, 5),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1)))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "    # Changed Features\n",
    "        # (!!!) Kernel Size = 5x5\n",
    "        # (!!!) Added strides = 1 for second CL and for second MaxPool\n",
    "        \n",
    "    # Unchanged Features\n",
    "        # Feature Maps = 16\n",
    "        # Max Pooling = 2x2 \n",
    "model2.add(Conv2D(16, (5, 5), strides=(1,1), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "# First hidden Layer of 120 nodes \n",
    "model2.add(Dense(120, activation='relu'))\n",
    "# Second hidden Layer of 84 nodes \n",
    "model2.add(Dense(84, activation='relu'))\n",
    "\n",
    "# Softmax layer with 10 nodes (based on 10 classes)\n",
    "model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# https://keras.io/optimizers/ \n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Store model as variable to plot learning error over epochs later\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot learning loss over epochs\n",
    "def plot_loss_accuracy(history2):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history2.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history2.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('5x5 KERNEL: Learning Error')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.grid(True)\n",
    "\n",
    "plot_loss_accuracy(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Changing Feature Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we:\n",
    "* **CHANGED FROM BOILERPLATE:** Change the number of feature maps in the first and second convolutional layers, added additional hyperparameters\n",
    "* Plot learning errors along the epoch\n",
    "* Report testing error\n",
    "* Report testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary modules\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten #imported more stuff\n",
    "from keras.optimizers import RMSprop #imported more stuff\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Imported More Stuff\n",
    "#from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      " 3968/60000 [>.............................] - ETA: 38s - loss: 1.8387 - accuracy: 0.4622"
     ]
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "# First Convolutional Layer\n",
    "    # Changed Features \n",
    "        # (!!!) CHANGED FROM BOILERPLATE: 8 Feature Maps\n",
    "        # (!!!) Added strides = 1 for first CL and for first MaxPool\n",
    "        # (!!!) Added additional hyperparameter: padding = 'valid'\n",
    "        \n",
    "    # Unchanged Features\n",
    "        # Max Pooling = 2x2\n",
    "model3.add(Conv2D(8, kernel_size=(5, 5),\n",
    "                 strides=(1,1),\n",
    "                 activation='relu',\n",
    "                 padding='valid',\n",
    "                 input_shape=input_shape))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1)))\n",
    "\n",
    "# Second Convolutional Layer\n",
    "    # Changed Features \n",
    "        # (!!!) CHANGED FROM BOILERPLATE: 20 Feature Maps\n",
    "        # (!!!) Added strides = 1 for second CL and for second MaxPool\n",
    "        # (!!!) Added additional hyperparameter: padding = 'valid'\n",
    "        \n",
    "    # Unchanged Features\n",
    "        # Feature Maps = 6\n",
    "model3.add(Conv2D(20, (5, 5), strides=(1,1), activation='relu', padding='valid'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1)))\n",
    "\n",
    "model3.add(Flatten())\n",
    "# First hidden Layer of 120 nodes \n",
    "model3.add(Dense(120, activation='relu'))\n",
    "# Second hidden Layer of 84 nodes \n",
    "model3.add(Dense(84, activation='relu'))\n",
    "\n",
    "# Softmax layer with 10 nodes (based on 10 classes)\n",
    "model3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# https://keras.io/optimizers/ \n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Store model as variable to plot learning error over epochs later\n",
    "history3 = model3.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history3):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.plot(history3.history[\"loss\"],'r-x', label=\"Train Loss\")\n",
    "    ax.plot(history3.history[\"val_loss\"],'b-x', label=\"Validation Loss\")\n",
    "    ax.legend()\n",
    "    ax.set_title('CHANGED FEATURE MAPS: Learning Error')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.grid(True)\n",
    "\n",
    "plot_loss_accuracy(history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model3.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
