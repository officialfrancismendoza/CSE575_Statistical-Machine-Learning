{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a CNN to classify images in the CIFAR-10 Dataset\n",
    "\n",
    "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The 10 classes are:\n",
    "\n",
    "<ol start=\"0\">\n",
    "<li> airplane\n",
    "<li>  automobile\n",
    "<li> bird\n",
    "<li>  cat\n",
    "<li> deer\n",
    "<li> dog\n",
    "<li>  frog\n",
    "<li>  horse\n",
    "<li>  ship\n",
    "<li>  truck\n",
    "</ol>\n",
    "\n",
    "For details about CIFAR-10 see:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "For a compilation of published performance results on CIFAR 10, see:\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
    "\n",
    "---\n",
    "\n",
    "### Building Convolutional Neural Nets\n",
    "\n",
    "In this exercise we will build and train our first convolutional neural networks.  In the first part, we walk through the different layers and how they are configured.  In the second part, you will build your own model, train it, and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Each image is a 32 x 32 x 3 numpy array\n",
    "x_train[444].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's look at one of the images\n",
    "\n",
    "print(y_train[444])\n",
    "plt.imshow(x_train[444]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\n",
    "y_train[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, let's make everything float and scale\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First CNN\n",
    "Below we will build our first CNN.  For demonstration purposes (so that it will train quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output.  After a MaxPooling layer, we flatten, and then have a single fully connected layer before our final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 181,162\n",
      "Trainable params: 181,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "\n",
    "## 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
    "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "## 2x2 max pooling reduces to 3 x 3 x 32\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(512))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_classes))\n",
    "model_1.add(Activation('softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 181K parameters, even though this is a \"small\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 18s 367us/step - loss: 1.7363 - accuracy: 0.3672 - val_loss: 1.6114 - val_accuracy: 0.4322\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 19s 371us/step - loss: 1.4584 - accuracy: 0.4736 - val_loss: 1.3857 - val_accuracy: 0.5032\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 1.3536 - accuracy: 0.5133 - val_loss: 1.3423 - val_accuracy: 0.5200\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.2841 - accuracy: 0.5425 - val_loss: 1.7646 - val_accuracy: 0.4171\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.2388 - accuracy: 0.5594 - val_loss: 1.1203 - val_accuracy: 0.6067\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 1.2020 - accuracy: 0.5739 - val_loss: 1.0997 - val_accuracy: 0.6157\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.1718 - accuracy: 0.5863 - val_loss: 1.0599 - val_accuracy: 0.6309\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.1562 - accuracy: 0.5946 - val_loss: 1.0789 - val_accuracy: 0.6266\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.1347 - accuracy: 0.6014 - val_loss: 1.0727 - val_accuracy: 0.6290\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 1.1237 - accuracy: 0.6113 - val_loss: 1.0563 - val_accuracy: 0.6342\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.1167 - accuracy: 0.6123 - val_loss: 1.1572 - val_accuracy: 0.5936\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.1067 - accuracy: 0.6175 - val_loss: 1.1108 - val_accuracy: 0.6087\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.1014 - accuracy: 0.6223 - val_loss: 1.0393 - val_accuracy: 0.6465\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.0930 - accuracy: 0.6235 - val_loss: 1.1300 - val_accuracy: 0.6148\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 1.0888 - accuracy: 0.6255 - val_loss: 1.0491 - val_accuracy: 0.6411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22875ff8d68>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0490906898498535\n",
      "Test accuracy: 0.6410999894142151\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MORE ACCURATE, MORE COMPUTATIONALLY-INTENSIVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "model_alt = Sequential()\n",
    "\n",
    "\n",
    "## 1st CNN Layer\n",
    "model_alt.add(Conv2D(32, (3, 3), strides = (1,1), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(Conv2D(32, (3, 3), strides = (1,1)))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_alt.add(Dropout(0.2))\n",
    "#-------------------------------------------------------------------\n",
    "## 2nd CNN Layer\n",
    "model_alt.add(Conv2D(64, (3, 3), strides = (1,1), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(Conv2D(64, (3, 3), strides = (1,1)))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "model_alt.add(Dropout(0.3))\n",
    "#-------------------------------------------------------------------\n",
    "## Flatten turns 3x3x32 into 288x1\n",
    "model_alt.add(Flatten())\n",
    "\n",
    "model_alt.add(Dense(512))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(Dropout(0.5))\n",
    "\n",
    "model_alt.add(Dense(512))\n",
    "model_alt.add(Activation('relu'))\n",
    "model_alt.add(Dropout(0.5))\n",
    "\n",
    "model_alt.add(Dense(num_classes))\n",
    "model_alt.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 30, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               25690624  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 26,023,978\n",
      "Trainable params: 26,023,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      " 9152/50000 [====>.........................] - ETA: 10:13 - loss: 1.9786 - accuracy: 0.2709"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f94bd1084a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m               shuffle=True)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\franc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_alt.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_alt.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=15,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_alt.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MY OWN MODEL\n",
    "> Test loss: 0.6803208335876465\n",
    "\n",
    "> Test accuracy: 0.8220999836921692\n",
    "\n",
    "# Attached are Pictures To Prove It. If you want faster compilation, shorten the # of epochs, although it will not model accuracy well. Total compilation time for 20 epochs ~80 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator( rotation_range=90,\n",
    "                 width_shift_range=0.1, height_shift_range=0.1,\n",
    "                 horizontal_flip=True)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a CNN using Keras' Sequential capabilities\n",
    "\n",
    "num_classes = 10\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(32, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.2))\n",
    " \n",
    "model_2.add(Conv2D(64, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(64, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.3))\n",
    " \n",
    "model_2.add(Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(Conv2D(128, (3,3), strides=(1,1), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model_2.add(Activation('elu'))\n",
    "model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_2.add(Dropout(0.4))\n",
    " \n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check number of parameters\n",
    "model_2.summary()\n",
    "\n",
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 289s 370ms/step - loss: 1.9305 - accuracy: 0.4158 - val_loss: 1.6042 - val_accuracy: 0.5232\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 295s 378ms/step - loss: 1.3079 - accuracy: 0.5791 - val_loss: 1.2620 - val_accuracy: 0.6147\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 298s 381ms/step - loss: 1.0970 - accuracy: 0.6478 - val_loss: 0.9723 - val_accuracy: 0.6956\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 298s 381ms/step - loss: 0.9883 - accuracy: 0.6886 - val_loss: 0.9419 - val_accuracy: 0.7175\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 293s 375ms/step - loss: 0.9252 - accuracy: 0.7121 - val_loss: 1.0836 - val_accuracy: 0.6914\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 301s 385ms/step - loss: 0.8747 - accuracy: 0.7318 - val_loss: 0.8490 - val_accuracy: 0.7558\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 309s 396ms/step - loss: 0.8409 - accuracy: 0.7452 - val_loss: 1.0766 - val_accuracy: 0.6947\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 316s 404ms/step - loss: 0.8082 - accuracy: 0.7577 - val_loss: 0.8356 - val_accuracy: 0.7673\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 305s 390ms/step - loss: 0.7913 - accuracy: 0.7663 - val_loss: 1.3014 - val_accuracy: 0.6371\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 298s 381ms/step - loss: 0.7768 - accuracy: 0.7716 - val_loss: 0.7493 - val_accuracy: 0.7917\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 293s 375ms/step - loss: 0.7609 - accuracy: 0.7779 - val_loss: 0.6843 - val_accuracy: 0.8126\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 291s 372ms/step - loss: 0.7456 - accuracy: 0.7843 - val_loss: 0.8004 - val_accuracy: 0.7763\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 291s 372ms/step - loss: 0.7354 - accuracy: 0.7902 - val_loss: 0.7429 - val_accuracy: 0.8002\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 290s 371ms/step - loss: 0.7204 - accuracy: 0.7949 - val_loss: 0.8178 - val_accuracy: 0.7784\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 288s 369ms/step - loss: 0.7112 - accuracy: 0.7989 - val_loss: 0.9556 - val_accuracy: 0.7417\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 305s 390ms/step - loss: 0.7061 - accuracy: 0.8017 - val_loss: 0.8141 - val_accuracy: 0.7844\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 296s 378ms/step - loss: 0.6986 - accuracy: 0.8043 - val_loss: 0.7422 - val_accuracy: 0.7985\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 306s 392ms/step - loss: 0.6849 - accuracy: 0.8090 - val_loss: 0.6372 - val_accuracy: 0.8298\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 304s 389ms/step - loss: 0.6814 - accuracy: 0.8109 - val_loss: 0.6683 - val_accuracy: 0.8258\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 297s 380ms/step - loss: 0.6799 - accuracy: 0.8131 - val_loss: 0.6803 - val_accuracy: 0.8221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27a46a15470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(datagen.flow(x_train, y_train,\n",
    "              batch_size=batch_size),\n",
    "              epochs=20,\n",
    "              validation_data=(x_test, y_test),\n",
    "            callbacks=[LearningRateScheduler(lr_schedule)]\n",
    "              #shuffle=True\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#training\\nbatch_size = 64\\n \\nopt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\\nmodel_2.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\\nmodel_2.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=100,                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\\n        \\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#training\n",
    "batch_size = 64\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model_2.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=100,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6803208335876465\n",
      "Test accuracy: 0.8220999836921692\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "\n",
    "# train the model using RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
